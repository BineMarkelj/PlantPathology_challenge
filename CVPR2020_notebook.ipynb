{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "753e874b",
   "metadata": {
    "papermill": {
     "duration": 0.017312,
     "end_time": "2024-06-12T16:03:09.466893",
     "exception": false,
     "start_time": "2024-06-12T16:03:09.449581",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# DL PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991f4b9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T14:29:54.469185600Z",
     "start_time": "2024-06-11T14:29:44.380828700Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-06-12T14:38:37.170821Z",
     "iopub.status.busy": "2024-06-12T14:38:37.170088Z",
     "iopub.status.idle": "2024-06-12T14:38:37.177414Z",
     "shell.execute_reply": "2024-06-12T14:38:37.176468Z",
     "shell.execute_reply.started": "2024-06-12T14:38:37.170789Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2024-06-12T16:03:09.483872",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# all installs\n",
    "#pip install torch torchvision torchaudio\n",
    "\n",
    "# all imports\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from torch.optim import Adam\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from torchvision.transforms import InterpolationMode\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n",
    "import timm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2081527",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Check for GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd37a43a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T14:29:57.238858500Z",
     "start_time": "2024-06-11T14:29:57.220557900Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-06-12T14:38:40.785587Z",
     "iopub.status.busy": "2024-06-12T14:38:40.784897Z",
     "iopub.status.idle": "2024-06-12T14:38:40.791198Z",
     "shell.execute_reply": "2024-06-12T14:38:40.790025Z",
     "shell.execute_reply.started": "2024-06-12T14:38:40.785558Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"CUDA is available. Using GPU.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"CUDA is not available. Using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f2cd72",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bb37ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T12:34:34.689984Z",
     "iopub.status.busy": "2024-06-12T12:34:34.689622Z",
     "iopub.status.idle": "2024-06-12T12:34:34.924123Z",
     "shell.execute_reply": "2024-06-12T12:34:34.923173Z",
     "shell.execute_reply.started": "2024-06-12T12:34:34.689954Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "# garbage collection\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177c8441",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T14:38:44.362298Z",
     "iopub.status.busy": "2024-06-12T14:38:44.361932Z",
     "iopub.status.idle": "2024-06-12T14:39:00.083524Z",
     "shell.execute_reply": "2024-06-12T14:39:00.082568Z",
     "shell.execute_reply.started": "2024-06-12T14:38:44.362271Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"/kaggle/input/plant-pathology-2020-fgvc7/train.csv\")\n",
    "test_df = pd.read_csv(\"/kaggle/input/plant-pathology-2020-fgvc7/test.csv\")\n",
    "\n",
    "\n",
    "images_path = \"/kaggle/input/plant-pathology-2020-fgvc7/images/\"\n",
    "\n",
    "class PlantDataset(Dataset):\n",
    "    def __init__(self, df, images_path, transform=None):\n",
    "        self.df = df\n",
    "        self.images_path = images_path\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.images_path, self.df.iloc[idx, 0] + \".jpg\")\n",
    "        image = Image.open(img_name)\n",
    "        image = image.convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        label = self.df.iloc[idx, 1:].values.astype(\"float\")\n",
    "\n",
    "        return image, torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "train_df = pd.read_csv(\"/kaggle/input/plant-pathology-2020-fgvc7/train.csv\")\n",
    "images_path = \"/kaggle/input/plant-pathology-2020-fgvc7/images/\"\n",
    "\n",
    "model_eff = timm.create_model('efficientnet_b4.ra2_in1k', pretrained=True)\n",
    "data_config_eff = timm.data.resolve_model_data_config(model_eff)\n",
    "transforms_eff = timm.data.create_transform(**data_config_eff, is_training=True)\n",
    "\n",
    "model_vit = timm.create_model('vit_base_patch16_224.augreg2_in21k_ft_in1k', pretrained=True)\n",
    "data_config_vit = timm.data.resolve_model_data_config(model_vit)\n",
    "transforms_vit = timm.data.create_transform(**data_config_vit, is_training=True)\n",
    "\n",
    "model_res = timm.create_model('resnet50.a1_in1k', pretrained=True)\n",
    "data_config_res = timm.data.resolve_model_data_config(model_res)\n",
    "transforms_res = timm.data.create_transform(**data_config_res, is_training=True)\n",
    "\n",
    "transforms_eff_val = transforms_eff\n",
    "transforms_vit_val = transforms_vit\n",
    "transforms_res_val = transforms_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71fcdee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T14:39:07.954691Z",
     "iopub.status.busy": "2024-06-12T14:39:07.954315Z",
     "iopub.status.idle": "2024-06-12T14:39:08.184520Z",
     "shell.execute_reply": "2024-06-12T14:39:08.183683Z",
     "shell.execute_reply.started": "2024-06-12T14:39:07.954658Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset_eff = PlantDataset(train_df, images_path, transform=transforms_eff)\n",
    "train_loader_eff = DataLoader(train_dataset_eff, batch_size=16, shuffle=True)\n",
    "\n",
    "train_dataset_vit = PlantDataset(train_df, images_path, transform=transforms_vit)\n",
    "train_loader_vit = DataLoader(train_dataset_vit, batch_size=16, shuffle=True)\n",
    "\n",
    "train_dataset_res = PlantDataset(train_df, images_path, transform=transforms_res)\n",
    "train_loader_res = DataLoader(train_dataset_res, batch_size=16, shuffle=True)\n",
    "\n",
    "# efficientnet b4\n",
    "class EfficientNetModel(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(EfficientNetModel, self).__init__()\n",
    "        self.model = timm.create_model('efficientnet_b4.ra2_in1k', pretrained=True)\n",
    "        self.model.classifier = nn.Linear(self.model.classifier.in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    \n",
    "# vision transformer\n",
    "class VisionTransformerModel(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(VisionTransformerModel, self).__init__()\n",
    "        self.model = timm.create_model('vit_base_patch16_224.augreg2_in21k_ft_in1k', pretrained=True)\n",
    "        self.model.head = nn.Linear(self.model.head.in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    \n",
    "# resnet50\n",
    "class ResNetModel(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(ResNetModel, self).__init__()\n",
    "        self.model = timm.create_model('resnet50.a1_in1k', pretrained=True)\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    \n",
    "# vitb\n",
    "class VisionTransformerBModel(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(VisionTransformerBModel, self).__init__()\n",
    "        self.model = timm.create_model('vit_base_patch14_reg4_dinov2.lvd142m', pretrained=True)\n",
    "        self.model.head = nn.Linear(self.model.embed_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    \n",
    "# TRAIN\n",
    "def train_epoch(model, dataloader, optimizer, criterion):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    progress_bar = tqdm(dataloader, desc=\"Training\", leave=False)\n",
    "    \n",
    "    for images, labels in progress_bar:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        progress_bar.set_postfix({'loss': loss.item()})\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    return epoch_loss\n",
    "\n",
    "\n",
    "# TEST\n",
    "def val_epoch(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    progress_bar = tqdm(dataloader, desc=\"Validating\", leave=False)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in progress_bar:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            progress_bar.set_postfix({'loss': loss.item()})\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dd4911",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T12:43:29.020722Z",
     "iopub.status.busy": "2024-06-12T12:43:29.020375Z",
     "iopub.status.idle": "2024-06-12T12:43:29.025714Z",
     "shell.execute_reply": "2024-06-12T12:43:29.024738Z",
     "shell.execute_reply.started": "2024-06-12T12:43:29.020697Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(len(train_loader_eff))\n",
    "print(len(val_loader_eff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b598b50d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T12:44:00.534572Z",
     "iopub.status.busy": "2024-06-12T12:44:00.533871Z",
     "iopub.status.idle": "2024-06-12T12:59:59.205959Z",
     "shell.execute_reply": "2024-06-12T12:59:59.205110Z",
     "shell.execute_reply.started": "2024-06-12T12:44:00.534541Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_eff = EfficientNetModel()\n",
    "\n",
    "\n",
    "model_eff.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer_eff = Adam(model_eff.parameters(), lr=0.0001)\n",
    "\n",
    "#scheduler_eff = ReduceLROnPlateau(optimizer_eff, mode='min', factor=0.5, patience=3, verbose=True)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    \n",
    "    #scheduler_eff.step()\n",
    "    #scheduler_vit.step()\n",
    "    \n",
    "    # efficientnet\n",
    "    train_loss_eff = train_epoch(model_eff, train_loader_eff, optimizer_eff, criterion)\n",
    "    \n",
    "    print(f\"EfficientNet: Train Loss: {train_loss_eff:.4f}\")\n",
    "    \n",
    "    #scheduler_eff.step(val_loss_eff)\n",
    "    \n",
    "    if (epoch % 5 == 0):\n",
    "        torch.save(model_eff.state_dict(), f'eff_tmp_{epoch+1}')\n",
    "        \n",
    "# save the final models\n",
    "torch.save(model_eff.state_dict(), \"eff_f_all.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b5ab71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T12:39:06.295618Z",
     "iopub.status.busy": "2024-06-12T12:39:06.294742Z",
     "iopub.status.idle": "2024-06-12T12:39:06.300316Z",
     "shell.execute_reply": "2024-06-12T12:39:06.299371Z",
     "shell.execute_reply.started": "2024-06-12T12:39:06.295585Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(len(train_loader_eff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bc6aba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T13:02:04.444000Z",
     "iopub.status.busy": "2024-06-12T13:02:04.443351Z",
     "iopub.status.idle": "2024-06-12T13:33:53.039052Z",
     "shell.execute_reply": "2024-06-12T13:33:53.038166Z",
     "shell.execute_reply.started": "2024-06-12T13:02:04.443972Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_res = ResNetModel()\n",
    "\n",
    "\n",
    "model_res.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer_res = Adam(model_res.parameters(), lr=0.0001)\n",
    "\n",
    "#scheduler_eff = ReduceLROnPlateau(optimizer_eff, mode='min', factor=0.5, patience=3, verbose=True)\n",
    "\n",
    "num_epochs = 30\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    \n",
    "    #scheduler_eff.step()\n",
    "    #scheduler_vit.step()\n",
    "    \n",
    "    # efficientnet\n",
    "    train_loss_res = train_epoch(model_res, train_loader_res, optimizer_res, criterion)\n",
    "    \n",
    "    print(f\"ResNet: Train Loss: {train_loss_res:.4f}\")\n",
    "    \n",
    "    #scheduler_eff.step(val_loss_eff)\n",
    "    \n",
    "    if (epoch % 5 == 0):\n",
    "        torch.save(model_res.state_dict(), f'res_tmp_{epoch+1}')\n",
    "        \n",
    "# save the final models\n",
    "torch.save(model_res.state_dict(), \"res_f_all.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbabaac0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T14:39:21.074086Z",
     "iopub.status.busy": "2024-06-12T14:39:21.073357Z",
     "iopub.status.idle": "2024-06-12T15:01:48.663336Z",
     "shell.execute_reply": "2024-06-12T15:01:48.662024Z",
     "shell.execute_reply.started": "2024-06-12T14:39:21.074053Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_vit = VisionTransformerModel()\n",
    "\n",
    "\n",
    "model_vit.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer_vit = Adam(model_vit.parameters(), lr=0.0001)\n",
    "\n",
    "#scheduler_eff = ReduceLROnPlateau(optimizer_eff, mode='min', factor=0.5, patience=3, verbose=True)\n",
    "\n",
    "num_epochs = 15\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    \n",
    "    #scheduler_eff.step()\n",
    "    #scheduler_vit.step()\n",
    "    \n",
    "    # efficientnet\n",
    "    train_loss_vit = train_epoch(model_vit, train_loader_vit, optimizer_vit, criterion)\n",
    "    \n",
    "    print(f\"VIT: Train Loss: {train_loss_vit:.4f}\")\n",
    "    \n",
    "    #scheduler_eff.step(val_loss_eff)\n",
    "    \n",
    "    if (epoch % 5 == 0):\n",
    "        torch.save(model_vit.state_dict(), f'vit_tmp_{epoch+1}')\n",
    "        \n",
    "# save the final models\n",
    "torch.save(model_vit.state_dict(), \"vit_f_all.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b70405",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109fe5d6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "All paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f726a1a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T14:29:58.976114400Z",
     "start_time": "2024-06-11T14:29:58.930337Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-06-12T08:49:26.042969Z",
     "iopub.status.busy": "2024-06-12T08:49:26.042364Z",
     "iopub.status.idle": "2024-06-12T08:49:26.066207Z",
     "shell.execute_reply": "2024-06-12T08:49:26.065396Z",
     "shell.execute_reply.started": "2024-06-12T08:49:26.042941Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"/kaggle/input/plant-pathology-2020-fgvc7/train.csv\")\n",
    "test_df = pd.read_csv(\"/kaggle/input/plant-pathology-2020-fgvc7/test.csv\")\n",
    "\n",
    "\n",
    "images_path = \"/kaggle/input/plant-pathology-2020-fgvc7/images/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9330a26b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Split the train data into train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b95d82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T14:30:00.183876700Z",
     "start_time": "2024-06-11T14:30:00.170870300Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-06-12T08:49:29.231736Z",
     "iopub.status.busy": "2024-06-12T08:49:29.231407Z",
     "iopub.status.idle": "2024-06-12T08:49:29.247124Z",
     "shell.execute_reply": "2024-06-12T08:49:29.246222Z",
     "shell.execute_reply.started": "2024-06-12T08:49:29.231710Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c12e9b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Dataset preparation\n",
    "Dataset class for the plant dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c038a2ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T14:30:02.009767500Z",
     "start_time": "2024-06-11T14:30:01.990804700Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-06-12T08:49:31.681904Z",
     "iopub.status.busy": "2024-06-12T08:49:31.681259Z",
     "iopub.status.idle": "2024-06-12T08:49:31.689326Z",
     "shell.execute_reply": "2024-06-12T08:49:31.688403Z",
     "shell.execute_reply.started": "2024-06-12T08:49:31.681872Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PlantDataset(Dataset):\n",
    "    def __init__(self, df, images_path, transform=None):\n",
    "        self.df = df\n",
    "        self.images_path = images_path\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.images_path, self.df.iloc[idx, 0] + \".jpg\")\n",
    "        image = Image.open(img_name)\n",
    "        image = image.convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        label = self.df.iloc[idx, 1:].values.astype(\"float\")\n",
    "\n",
    "        return image, torch.tensor(label, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1933843b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b59571",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T14:30:16.151600400Z",
     "start_time": "2024-06-11T14:30:03.448005500Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-06-12T08:49:36.881985Z",
     "iopub.status.busy": "2024-06-12T08:49:36.881175Z",
     "iopub.status.idle": "2024-06-12T08:49:50.583855Z",
     "shell.execute_reply": "2024-06-12T08:49:50.582904Z",
     "shell.execute_reply.started": "2024-06-12T08:49:36.881950Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_eff = timm.create_model('efficientnet_b4.ra2_in1k', pretrained=True)\n",
    "data_config_eff = timm.data.resolve_model_data_config(model_eff)\n",
    "transforms_eff = timm.data.create_transform(**data_config_eff, is_training=True)\n",
    "\n",
    "model_vit = timm.create_model('vit_base_patch16_224.augreg2_in21k_ft_in1k', pretrained=True)\n",
    "data_config_vit = timm.data.resolve_model_data_config(model_vit)\n",
    "transforms_vit = timm.data.create_transform(**data_config_vit, is_training=True)\n",
    "\n",
    "model_res = timm.create_model('resnet50.a1_in1k', pretrained=True)\n",
    "data_config_res = timm.data.resolve_model_data_config(model_res)\n",
    "transforms_res = timm.data.create_transform(**data_config_res, is_training=True)\n",
    "\n",
    "#model_vitb = timm.create_model('vit_base_patch14_reg4_dinov2.lvd142m', pretrained=True)\n",
    "#data_config_vitb = timm.data.resolve_model_data_config(model_vitb)\n",
    "#transforms_vitb = timm.data.create_transform(**data_config_vitb, is_training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0256d377",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T14:30:18.273778900Z",
     "start_time": "2024-06-11T14:30:18.229316800Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-06-12T08:51:58.982531Z",
     "iopub.status.busy": "2024-06-12T08:51:58.982138Z",
     "iopub.status.idle": "2024-06-12T08:51:59.010130Z",
     "shell.execute_reply": "2024-06-12T08:51:59.009247Z",
     "shell.execute_reply.started": "2024-06-12T08:51:58.982500Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(transforms_eff)\n",
    "print(transforms_vit)\n",
    "print(transforms_res)\n",
    "#print(transforms_vitb)\n",
    "\n",
    "transforms_eff_val = transforms_eff\n",
    "transforms_vit_val = transforms_vit\n",
    "transforms_res_val = transforms_res\n",
    "#transforms_vitb_val = transforms_vitb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4533cd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T14:37:49.364263Z",
     "start_time": "2024-06-11T14:37:49.314369300Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-06-11T14:53:07.658091Z",
     "iopub.status.busy": "2024-06-11T14:53:07.657637Z",
     "iopub.status.idle": "2024-06-11T14:53:07.669207Z",
     "shell.execute_reply": "2024-06-11T14:53:07.668190Z",
     "shell.execute_reply.started": "2024-06-11T14:53:07.658055Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "transforms_eff = transforms.Compose([\n",
    "    transforms.Resize(345, interpolation=InterpolationMode.BICUBIC),\n",
    "    transforms.CenterCrop(320),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    #transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    #transforms.ColorJitter(brightness=(0.9, 1.05), contrast=(0.88, 1.2), saturation=(0.9, 1.1), hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "transforms_vit = transforms.Compose([\n",
    "    transforms.Resize(232, interpolation=InterpolationMode.BICUBIC),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    #transforms.ColorJitter(brightness=(0.9, 1.2), contrast=(0.9, 1.1), saturation=(0.9, 1.1), hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "transforms_eff_val = transforms.Compose([\n",
    "    transforms.Resize(345, interpolation=InterpolationMode.BICUBIC),\n",
    "    transforms.CenterCrop(320),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "transforms_vit_val = transforms.Compose([\n",
    "    transforms.Resize(232, interpolation=InterpolationMode.BICUBIC),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b178053",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Create the datasets, dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ab093d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T14:37:51.306558900Z",
     "start_time": "2024-06-11T14:37:51.296888200Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-06-12T08:52:29.502620Z",
     "iopub.status.busy": "2024-06-12T08:52:29.501773Z",
     "iopub.status.idle": "2024-06-12T08:52:29.513694Z",
     "shell.execute_reply": "2024-06-12T08:52:29.512672Z",
     "shell.execute_reply.started": "2024-06-12T08:52:29.502577Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset_eff = PlantDataset(train_df, images_path, transform=transforms_eff)\n",
    "val_dataset_eff = PlantDataset(val_df, images_path, transform=transforms_eff_val)\n",
    "train_loader_eff = DataLoader(train_dataset_eff, batch_size=16, shuffle=True)\n",
    "val_loader_eff = DataLoader(val_dataset_eff, batch_size=16, shuffle=False)\n",
    "\n",
    "train_dataset_vit = PlantDataset(train_df, images_path, transform=transforms_vit)\n",
    "val_dataset_vit = PlantDataset(val_df, images_path, transform=transforms_vit_val)\n",
    "train_loader_vit = DataLoader(train_dataset_vit, batch_size=16, shuffle=True)\n",
    "val_loader_vit = DataLoader(val_dataset_vit, batch_size=16, shuffle=False)\n",
    "\n",
    "train_dataset_res = PlantDataset(train_df, images_path, transform=transforms_res)\n",
    "val_dataset_res = PlantDataset(val_df, images_path, transform=transforms_res_val)\n",
    "train_loader_res = DataLoader(train_dataset_res, batch_size=16, shuffle=True)\n",
    "val_loader_res = DataLoader(val_dataset_res, batch_size=16, shuffle=False)\n",
    "\n",
    "#train_dataset_vitb = PlantDataset(train_df, images_path, transform=transforms_vitb)\n",
    "#val_dataset_vitb = PlantDataset(val_df, images_path, transform=transforms_vitb_val)\n",
    "#train_loader_vitb = DataLoader(train_dataset_vitb, batch_size=8, shuffle=True)\n",
    "#val_loader_vitb = DataLoader(val_dataset_vitb, batch_size=8, shuffle=False)\n",
    "\n",
    "\n",
    "#test_dataset = PlantDataset(test_df, images_path, transform=val_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530f0f3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T14:37:56.908211700Z",
     "start_time": "2024-06-11T14:37:52.459242400Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-06-11T19:27:15.935261Z",
     "iopub.status.busy": "2024-06-11T19:27:15.934880Z",
     "iopub.status.idle": "2024-06-11T19:27:25.099423Z",
     "shell.execute_reply": "2024-06-11T19:27:25.098324Z",
     "shell.execute_reply.started": "2024-06-11T19:27:15.935219Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(24, 12))\n",
    "columns = 4\n",
    "rows = 2\n",
    "\n",
    "for i in range(columns * rows):\n",
    "    input, label = train_dataset_eff[np.random.randint(len(train_dataset_eff))]\n",
    "    print(label)\n",
    "    img = input.detach().numpy().transpose((1, 2, 0))\n",
    "\n",
    "    ax = fig.add_subplot(rows, columns, i + 1)\n",
    "    label_names = str(label).replace(\"'\", \"\").replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "    ax.set_title(label_names, fontstyle='italic')\n",
    "    plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig=plt.figure(figsize=(24, 12))\n",
    "columns = 4\n",
    "rows = 2\n",
    "\n",
    "for i in range(columns * rows):\n",
    "    input, label = train_dataset_vit[np.random.randint(len(train_dataset_vit))]\n",
    "    print(label)\n",
    "    img = input.detach().numpy().transpose((1, 2, 0))\n",
    "\n",
    "    ax = fig.add_subplot(rows, columns, i + 1)\n",
    "    label_names = str(label).replace(\"'\", \"\").replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "    ax.set_title(label_names, fontstyle='italic')\n",
    "    plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "fig=plt.figure(figsize=(24, 12))\n",
    "columns = 4\n",
    "rows = 2\n",
    "\n",
    "for i in range(columns * rows):\n",
    "    input, label = train_dataset_res[np.random.randint(len(train_dataset_res))]\n",
    "    print(label)\n",
    "    img = input.detach().numpy().transpose((1, 2, 0))\n",
    "\n",
    "    ax = fig.add_subplot(rows, columns, i + 1)\n",
    "    label_names = str(label).replace(\"'\", \"\").replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "    ax.set_title(label_names, fontstyle='italic')\n",
    "    plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "fig=plt.figure(figsize=(24, 12))\n",
    "columns = 4\n",
    "rows = 2\n",
    "\n",
    "for i in range(columns * rows):\n",
    "    input, label = train_dataset_vitb[np.random.randint(len(train_dataset_vitb))]\n",
    "    print(label)\n",
    "    img = input.detach().numpy().transpose((1, 2, 0))\n",
    "\n",
    "    ax = fig.add_subplot(rows, columns, i + 1)\n",
    "    label_names = str(label).replace(\"'\", \"\").replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "    ax.set_title(label_names, fontstyle='italic')\n",
    "    plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5419e1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Models\n",
    "Idea:\n",
    "- use 2 separate models: efficientnet and vision transformer\n",
    "- finally avg the outputs of both models -> this is the final output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5989fca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T14:38:31.522732300Z",
     "start_time": "2024-06-11T14:38:31.516862700Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-06-12T08:52:39.132444Z",
     "iopub.status.busy": "2024-06-12T08:52:39.132097Z",
     "iopub.status.idle": "2024-06-12T08:52:39.144016Z",
     "shell.execute_reply": "2024-06-12T08:52:39.143166Z",
     "shell.execute_reply.started": "2024-06-12T08:52:39.132418Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# efficientnet b4\n",
    "class EfficientNetModel(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(EfficientNetModel, self).__init__()\n",
    "        self.model = timm.create_model('efficientnet_b4.ra2_in1k', pretrained=True)\n",
    "        self.model.classifier = nn.Linear(self.model.classifier.in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    \n",
    "# vision transformer\n",
    "class VisionTransformerModel(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(VisionTransformerModel, self).__init__()\n",
    "        self.model = timm.create_model('vit_base_patch16_224.augreg2_in21k_ft_in1k', pretrained=True)\n",
    "        self.model.head = nn.Linear(self.model.head.in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    \n",
    "# resnet50\n",
    "class ResNetModel(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(ResNetModel, self).__init__()\n",
    "        self.model = timm.create_model('resnet50.a1_in1k', pretrained=True)\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    \n",
    "# vitb\n",
    "class VisionTransformerBModel(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(VisionTransformerBModel, self).__init__()\n",
    "        self.model = timm.create_model('vit_base_patch14_reg4_dinov2.lvd142m', pretrained=True)\n",
    "        self.model.head = nn.Linear(self.model.embed_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6f97c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T14:38:36.246896900Z",
     "start_time": "2024-06-11T14:38:32.702691700Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-06-12T08:52:45.922142Z",
     "iopub.status.busy": "2024-06-12T08:52:45.921441Z",
     "iopub.status.idle": "2024-06-12T08:52:49.095305Z",
     "shell.execute_reply": "2024-06-12T08:52:49.094545Z",
     "shell.execute_reply.started": "2024-06-12T08:52:45.922112Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101814f0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Training loop, validation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1edacd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T14:38:43.680474200Z",
     "start_time": "2024-06-11T14:38:43.659996100Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-06-12T08:52:53.642097Z",
     "iopub.status.busy": "2024-06-12T08:52:53.641393Z",
     "iopub.status.idle": "2024-06-12T08:52:53.651456Z",
     "shell.execute_reply": "2024-06-12T08:52:53.650555Z",
     "shell.execute_reply.started": "2024-06-12T08:52:53.642063Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TRAIN\n",
    "def train_epoch(model, dataloader, optimizer, criterion):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    progress_bar = tqdm(dataloader, desc=\"Training\", leave=False)\n",
    "    \n",
    "    for images, labels in progress_bar:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        progress_bar.set_postfix({'loss': loss.item()})\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    return epoch_loss\n",
    "\n",
    "\n",
    "# TEST\n",
    "def val_epoch(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    progress_bar = tqdm(dataloader, desc=\"Validating\", leave=False)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in progress_bar:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            progress_bar.set_postfix({'loss': loss.item()})\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8533616",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6f9d13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T14:39:35.251972700Z",
     "start_time": "2024-06-11T14:39:14.055705400Z"
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-06-12T08:55:56.752843Z",
     "iopub.status.busy": "2024-06-12T08:55:56.752462Z",
     "iopub.status.idle": "2024-06-12T11:27:39.540247Z",
     "shell.execute_reply": "2024-06-12T11:27:39.539141Z",
     "shell.execute_reply.started": "2024-06-12T08:55:56.752814Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_eff = EfficientNetModel()\n",
    "model_vit = VisionTransformerModel()\n",
    "model_res = ResNetModel()\n",
    "model_vitb = VisionTransformerBModel()\n",
    "\n",
    "model_eff.to(device)\n",
    "model_vit.to(device)\n",
    "model_res.to(device)\n",
    "model_vitb.to(device)\n",
    "\n",
    "#criterion = nn.BCEWithLogitsLoss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer_eff = Adam(model_eff.parameters(), lr=0.0001)\n",
    "optimizer_vit = Adam(model_vit.parameters(), lr=0.0001)\n",
    "optimizer_res = Adam(model_res.parameters(), lr=0.0001)\n",
    "optimizer_vitb = Adam(model_vitb.parameters(), lr=0.0001)\n",
    "\n",
    "scheduler_eff = ReduceLROnPlateau(optimizer_eff, mode='min', factor=0.5, patience=3, verbose=True)\n",
    "scheduler_vit = ReduceLROnPlateau(optimizer_vit, mode='min', factor=0.5, patience=3, verbose=True)\n",
    "scheduler_res = ReduceLROnPlateau(optimizer_res, mode='min', factor=0.5, patience=3, verbose=True)\n",
    "scheduler_vitb = ReduceLROnPlateau(optimizer_vitb, mode='min', factor=0.5, patience=3, verbose=True)\n",
    "\n",
    "num_epochs = 40\n",
    "\n",
    "train_losses_eff = []\n",
    "val_losses_eff = []\n",
    "\n",
    "train_losses_vit = []\n",
    "val_losses_vit = []\n",
    "\n",
    "train_losses_res = []\n",
    "val_losses_res = []\n",
    "\n",
    "train_losses_vitb = []\n",
    "val_losses_vitb = []\n",
    "\n",
    "best_model_eff = None\n",
    "best_val_loss_eff = np.inf\n",
    "\n",
    "best_model_vit = None\n",
    "best_val_loss_vit = np.inf\n",
    "\n",
    "best_model_res = None\n",
    "best_val_loss_res = np.inf\n",
    "\n",
    "best_model_vitb = None\n",
    "best_val_loss_vitb = np.inf\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    \n",
    "    #scheduler_eff.step()\n",
    "    #scheduler_vit.step()\n",
    "    \n",
    "    # efficientnet\n",
    "    train_loss_eff = train_epoch(model_eff, train_loader_eff, optimizer_eff, criterion)\n",
    "    val_loss_eff = val_epoch(model_eff, val_loader_eff, criterion)\n",
    "    train_losses_eff.append(train_loss_eff)\n",
    "    val_losses_eff.append(val_loss_eff)\n",
    "    \n",
    "    \n",
    "    # vit\n",
    "    train_loss_vit = train_epoch(model_vit, train_loader_vit, optimizer_vit, criterion)\n",
    "    val_loss_vit = val_epoch(model_vit, val_loader_vit, criterion)  \n",
    "    train_losses_vit.append(train_loss_vit)\n",
    "    val_losses_vit.append(val_loss_vit)\n",
    "    \n",
    "    \n",
    "    # res\n",
    "    train_loss_res = train_epoch(model_res, train_loader_res, optimizer_res, criterion)\n",
    "    val_loss_res = val_epoch(model_res, val_loader_res, criterion)\n",
    "    train_losses_res.append(train_loss_res)\n",
    "    val_losses_res.append(val_loss_res)\n",
    "    \n",
    "    # vitb\n",
    "    train_loss_vitb = train_epoch(model_vitb, train_loader_vitb, optimizer_vitb, criterion)\n",
    "    val_loss_vitb = val_epoch(model_vitb, val_loader_vitb, criterion)\n",
    "    train_losses_vitb.append(train_loss_vitb)\n",
    "    val_losses_vitb.append(val_loss_vitb)\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(f\"EfficientNet: Train Loss: {train_loss_eff:.4f}, Val Loss: {val_loss_eff:.4f}\")\n",
    "    print(f\"Vision Transformer: Train Loss: {train_loss_vit:.4f}, Val Loss: {val_loss_vit:.4f}\")\n",
    "    print(f\"ResNet: Train Loss: {train_loss_res:.4f}, Val Loss: {val_loss_res:.4f}\")\n",
    "    print(f\"Vision Transformer Better: Train Loss: {train_loss_vitb:.4f}, Val Loss: {val_loss_vitb:.4f}\")\n",
    "    \n",
    "    scheduler_eff.step(val_loss_eff)\n",
    "    scheduler_vit.step(val_loss_vit)\n",
    "    scheduler_res.step(val_loss_vit)\n",
    "    scheduler_vitb.step(val_loss_vit)\n",
    "    \n",
    "    if val_loss_eff < best_val_loss_eff:\n",
    "        best_val_loss_eff = val_loss_eff\n",
    "        best_model_eff = copy.deepcopy(model_eff)\n",
    "        # save the model\n",
    "        torch.save(best_model_eff.state_dict(), \"best_model_eff.pth\")\n",
    "        print(\"eff saved\")\n",
    "        \n",
    "    if val_loss_vit < best_val_loss_vit:\n",
    "        best_val_loss_vit = val_loss_vit\n",
    "        best_model_vit = copy.deepcopy(model_vit)\n",
    "        # save the model\n",
    "        torch.save(best_model_vit.state_dict(), \"best_model_vit.pth\")\n",
    "        print(\"vit saved\")\n",
    "        \n",
    "    if val_loss_res < best_val_loss_res:\n",
    "        best_val_loss_res = val_loss_res\n",
    "        best_model_res = copy.deepcopy(model_res)\n",
    "        # save the model\n",
    "        torch.save(best_model_res.state_dict(), \"best_model_res.pth\")\n",
    "        print(\"res saved\")\n",
    "        \n",
    "    if val_loss_vitb < best_val_loss_vitb:\n",
    "        best_val_loss_vitb = val_loss_vitb\n",
    "        best_model_vitb = copy.deepcopy(model_vitb)\n",
    "        # save the model\n",
    "        torch.save(best_model_vitb.state_dict(), \"best_model_vitb.pth\")\n",
    "        print(\"vitb saved\")\n",
    "        \n",
    "# save the final models\n",
    "torch.save(model_eff.state_dict(), \"final_model_eff.pth\")\n",
    "torch.save(model_vit.state_dict(), \"final_model_vit.pth\")\n",
    "torch.save(model_res.state_dict(), \"final_model_res.pth\")\n",
    "torch.save(model_vitb.state_dict(), \"final_model_vitb.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c184cad",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Plot the training and validation losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db560863",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-06-12T11:28:35.720603Z",
     "iopub.status.busy": "2024-06-12T11:28:35.720235Z",
     "iopub.status.idle": "2024-06-12T11:28:36.492090Z",
     "shell.execute_reply": "2024-06-12T11:28:36.491269Z",
     "shell.execute_reply.started": "2024-06-12T11:28:35.720573Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(train_losses_eff, label=\"Train Loss EfficientNet\")\n",
    "plt.plot(val_losses_eff, label=\"Val Loss EfficientNet\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(train_losses_vit, label=\"Train Loss VIT\")\n",
    "plt.plot(val_losses_vit, label=\"Val Loss VIT\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(train_losses_res, label=\"Train Loss ResNet\")\n",
    "plt.plot(val_losses_res, label=\"Val Loss ResNet\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(train_losses_vitb, label=\"Train Loss VIT-B\")\n",
    "plt.plot(val_losses_vitb, label=\"Val Loss VIT-B\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(train_losses_eff)\n",
    "print(val_losses_eff)\n",
    "\n",
    "print(train_losses_res)\n",
    "print(val_losses_res)\n",
    "\n",
    "print(train_losses_vit)\n",
    "print(val_losses_vit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcc335f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Test the model, predict and save the results\n",
    "\n",
    "3 approahes:\n",
    "- only efficientnet\n",
    "- only vision transformer\n",
    "- avg of both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b072bf64",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-06-12T15:02:22.700388Z",
     "iopub.status.busy": "2024-06-12T15:02:22.699468Z",
     "iopub.status.idle": "2024-06-12T15:02:22.706926Z",
     "shell.execute_reply": "2024-06-12T15:02:22.705856Z",
     "shell.execute_reply.started": "2024-06-12T15:02:22.700354Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# predict \n",
    "def predict(model, dataloader):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    \n",
    "    progress_bar = tqdm(dataloader, desc=\"Predicting\", leave=False)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in progress_bar:\n",
    "            images = images.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            #print(outputs)\n",
    "            #print(outputs.shape)\n",
    "            \n",
    "            probabilities = F.softmax(outputs, dim=1)\n",
    "            predictions.append(probabilities.cpu().numpy())\n",
    "    \n",
    "    return np.concatenate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5e6649",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-06-12T15:03:32.478041Z",
     "iopub.status.busy": "2024-06-12T15:03:32.477667Z",
     "iopub.status.idle": "2024-06-12T15:03:36.185033Z",
     "shell.execute_reply": "2024-06-12T15:03:36.184067Z",
     "shell.execute_reply.started": "2024-06-12T15:03:32.478011Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load the best models\n",
    "model_eff = EfficientNetModel()\n",
    "model_vit = VisionTransformerModel()\n",
    "model_res = ResNetModel()\n",
    "model_vitb = VisionTransformerBModel()\n",
    "\n",
    "model_eff.load_state_dict(torch.load(\"eff_f_all.pth\"))\n",
    "model_vit.load_state_dict(torch.load(\"vit_f_all.pth\"))\n",
    "model_res.load_state_dict(torch.load(\"res_f_all.pth\"))\n",
    "model_vitb.load_state_dict(torch.load(\"best_model_vitb.pth\"))\n",
    "\n",
    "model_eff.to(device)\n",
    "model_vit.to(device)\n",
    "model_res.to(device)\n",
    "model_vitb.to(device)\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f36a47",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-06-12T15:03:43.332363Z",
     "iopub.status.busy": "2024-06-12T15:03:43.331708Z",
     "iopub.status.idle": "2024-06-12T15:07:13.809668Z",
     "shell.execute_reply": "2024-06-12T15:07:13.808649Z",
     "shell.execute_reply.started": "2024-06-12T15:03:43.332329Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataset_eff = PlantDataset(test_df, images_path, transform=transforms_eff_val)\n",
    "test_loader_eff = DataLoader(test_dataset_eff, batch_size=8, shuffle=False)\n",
    "\n",
    "test_dataset_vit = PlantDataset(test_df, images_path, transform=transforms_vit_val)\n",
    "test_loader_vit = DataLoader(test_dataset_vit, batch_size=8, shuffle=False)\n",
    "\n",
    "test_dataset_res = PlantDataset(test_df, images_path, transform=transforms_res_val)\n",
    "test_loader_res = DataLoader(test_dataset_res, batch_size=8, shuffle=False)\n",
    "\n",
    "test_dataset_vitb = PlantDataset(test_df, images_path, transform=transforms_vitb_val)\n",
    "test_loader_vitb = DataLoader(test_dataset_vitb, batch_size=8, shuffle=False)\n",
    "\n",
    "# eff predict\n",
    "predictions_eff = predict(model_eff, test_loader_eff)\n",
    "\n",
    "# vit predict\n",
    "predictions_vit = predict(model_vit, test_loader_vit)\n",
    "\n",
    "# res predict\n",
    "predictions_res = predict(model_res, test_loader_res)\n",
    "\n",
    "# vitb predict\n",
    "predictions_vitb = predict(model_vitb, test_loader_vitb)\n",
    "\n",
    "# avg predict\n",
    "predictions_avg = (predictions_eff + predictions_vit + predictions_res) / 3\n",
    "\n",
    "# save the predictions into 3 separate files\n",
    "submissions_eff = pd.DataFrame(predictions_eff, columns=[\"healthy\", \"multiple_diseases\", \"rust\", \"scab\"])\n",
    "submissions_eff[\"image_id\"] = test_df[\"image_id\"]\n",
    "submissions_eff = submissions_eff[[\"image_id\", \"healthy\", \"multiple_diseases\", \"rust\", \"scab\"]]\n",
    "submissions_eff.to_csv(\"submission_eff.csv\", index=False)\n",
    "\n",
    "submissions_vit = pd.DataFrame(predictions_vit, columns=[\"healthy\", \"multiple_diseases\", \"rust\", \"scab\"])\n",
    "submissions_vit[\"image_id\"] = test_df[\"image_id\"]\n",
    "submissions_vit = submissions_vit[[\"image_id\", \"healthy\", \"multiple_diseases\", \"rust\", \"scab\"]]\n",
    "submissions_vit.to_csv(\"submission_vit.csv\", index=False)\n",
    "\n",
    "submissions_res = pd.DataFrame(predictions_res, columns=[\"healthy\", \"multiple_diseases\", \"rust\", \"scab\"])\n",
    "submissions_res[\"image_id\"] = test_df[\"image_id\"]\n",
    "submissions_res = submissions_res[[\"image_id\", \"healthy\", \"multiple_diseases\", \"rust\", \"scab\"]]\n",
    "submissions_res.to_csv(\"submission_res.csv\", index=False)\n",
    "\n",
    "submissions_vitb = pd.DataFrame(predictions_vitb, columns=[\"healthy\", \"multiple_diseases\", \"rust\", \"scab\"])\n",
    "submissions_vitb[\"image_id\"] = test_df[\"image_id\"]\n",
    "submissions_vitb = submissions_vitb[[\"image_id\", \"healthy\", \"multiple_diseases\", \"rust\", \"scab\"]]\n",
    "submissions_vitb.to_csv(\"submission_vitb.csv\", index=False)\n",
    "\n",
    "submissions_avg = pd.DataFrame(predictions_avg, columns=[\"healthy\", \"multiple_diseases\", \"rust\", \"scab\"])\n",
    "submissions_avg[\"image_id\"] = test_df[\"image_id\"]\n",
    "submissions_avg = submissions_avg[[\"image_id\", \"healthy\", \"multiple_diseases\", \"rust\", \"scab\"]]\n",
    "submissions_avg.to_csv(\"submission_avg.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2fca21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T15:07:51.100706Z",
     "iopub.status.busy": "2024-06-12T15:07:51.100301Z",
     "iopub.status.idle": "2024-06-12T15:07:51.121581Z",
     "shell.execute_reply": "2024-06-12T15:07:51.120634Z",
     "shell.execute_reply.started": "2024-06-12T15:07:51.100673Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions_avg_3 = (predictions_eff + predictions_vit + predictions_res) / 3\n",
    "predictions_avg_3 = pd.DataFrame(predictions_avg_3, columns=[\"healthy\", \"multiple_diseases\", \"rust\", \"scab\"])\n",
    "predictions_avg_3[\"image_id\"] = test_df[\"image_id\"]\n",
    "predictions_avg_3 = submissions_avg[[\"image_id\", \"healthy\", \"multiple_diseases\", \"rust\", \"scab\"]]\n",
    "predictions_avg_3.to_csv(\"submission_avg3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798abc6e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now combine all 4 models into 1 - train a seperate model that intakes embeddings from all 4 models and predicts the final output\n",
    "\n",
    "class EnsembleModel(nn.Module):\n",
    "    def __init__(self, num_classes=4, input_dim=4096):\n",
    "        super(EnsembleModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 1024)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.dropout3 = nn.Dropout(0.5)\n",
    "        \n",
    "        self.fc4 = nn.Linear(256, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.dropout3(x)\n",
    "        \n",
    "        x = self.fc4(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7875b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T01:13:14.451415Z",
     "iopub.status.busy": "2024-06-12T01:13:14.451011Z",
     "iopub.status.idle": "2024-06-12T01:13:14.460159Z",
     "shell.execute_reply": "2024-06-12T01:13:14.459058Z",
     "shell.execute_reply.started": "2024-06-12T01:13:14.451387Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_all_embeddings(model, dataloader):\n",
    "    model.eval()\n",
    "    embeddings = []\n",
    "    labels = []\n",
    "    \n",
    "    progress_bar = tqdm(dataloader, desc=\"Getting Embeddings\", leave=False)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, targets in progress_bar:\n",
    "            images = images.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            embeddings.append(outputs.cpu().numpy())\n",
    "            labels.append(targets.cpu().numpy())\n",
    "            \n",
    "        embeddings = np.concatenate(embeddings)\n",
    "        labels = np.concatenate(labels)\n",
    "    \n",
    "    return embeddings, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827706b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T01:13:20.545840Z",
     "iopub.status.busy": "2024-06-12T01:13:20.545162Z",
     "iopub.status.idle": "2024-06-12T01:18:53.164991Z",
     "shell.execute_reply": "2024-06-12T01:18:53.164027Z",
     "shell.execute_reply.started": "2024-06-12T01:13:20.545808Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load the best models\n",
    "model_eff = EfficientNetModel()\n",
    "model_vit = VisionTransformerModel()\n",
    "model_res = ResNetModel()\n",
    "model_vitb = VisionTransformerBModel()\n",
    "\n",
    "model_eff.load_state_dict(torch.load(\"best_model_eff.pth\"))\n",
    "model_vit.load_state_dict(torch.load(\"best_model_vit.pth\"))\n",
    "model_res.load_state_dict(torch.load(\"best_model_res.pth\"))\n",
    "model_vitb.load_state_dict(torch.load(\"best_model_vitb.pth\"))\n",
    "\n",
    "# for each model remove the last layer\n",
    "model_eff.model.classifier = nn.Identity()\n",
    "model_vit.model.head = nn.Identity()\n",
    "model_res.model.fc = nn.Identity()\n",
    "model_vitb.model.head = nn.Identity()\n",
    "\n",
    "model_eff.to(device)\n",
    "model_vit.to(device)\n",
    "model_res.to(device)\n",
    "model_vitb.to(device)\n",
    "\n",
    "# get the embeddings\n",
    "train_embeddings_eff, train_labels_eff = get_all_embeddings(model_eff, train_loader_eff)\n",
    "train_embeddings_vit, train_labels_vit = get_all_embeddings(model_vit, train_loader_vit)\n",
    "train_embeddings_res, train_labels_res = get_all_embeddings(model_res, train_loader_res)\n",
    "train_embeddings_vitb, train_labels_vitb = get_all_embeddings(model_vitb, train_loader_vitb)\n",
    "\n",
    "print(f'sizes: {train_embeddings_eff.shape}, {train_embeddings_vit.shape}, {train_embeddings_res.shape}')\n",
    "\n",
    "# combine the embeddings\n",
    "train_embeddings = np.concatenate([train_embeddings_eff, train_embeddings_vit, train_embeddings_res, axis=1)\n",
    "\n",
    "size = train_embeddings.shape[1]\n",
    "\n",
    "# create the ensemble model\n",
    "ensemble_model = EnsembleModel(num_classes=4, input_dim=size)\n",
    "ensemble_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e45057",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T01:19:24.153485Z",
     "iopub.status.busy": "2024-06-12T01:19:24.152681Z",
     "iopub.status.idle": "2024-06-12T01:19:24.158437Z",
     "shell.execute_reply": "2024-06-12T01:19:24.157420Z",
     "shell.execute_reply.started": "2024-06-12T01:19:24.153449Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(train_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be33f0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T01:19:29.177734Z",
     "iopub.status.busy": "2024-06-12T01:19:29.176888Z",
     "iopub.status.idle": "2024-06-12T01:20:48.533568Z",
     "shell.execute_reply": "2024-06-12T01:20:48.532668Z",
     "shell.execute_reply.started": "2024-06-12T01:19:29.177703Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_embeddings_eff, val_labels_eff = get_all_embeddings(model_eff, val_loader_eff)\n",
    "val_embeddings_vit, val_labels_vit = get_all_embeddings(model_vit, val_loader_vit)\n",
    "val_embeddings_res, val_labels_res = get_all_embeddings(model_res, val_loader_res)\n",
    "val_embeddings_vitb, val_labels_vitb = get_all_embeddings(model_vitb, val_loader_vitb)\n",
    "\n",
    "val_embeddings = np.concatenate([val_embeddings_eff, val_embeddings_vit, val_embeddings_res], axis=1)\n",
    "\n",
    "val_labels_eff = torch.tensor(val_labels_eff, dtype=torch.long).to(device)\n",
    "val_labels_vit = torch.tensor(val_labels_vit, dtype=torch.long).to(device)\n",
    "val_labels_res = torch.tensor(val_labels_res, dtype=torch.long).to(device)\n",
    "val_labels_vitb = torch.tensor(val_labels_vitb, dtype=torch.long).to(device)\n",
    "\n",
    "print(val_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d95ee4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T01:24:26.799695Z",
     "iopub.status.busy": "2024-06-12T01:24:26.799233Z",
     "iopub.status.idle": "2024-06-12T01:24:26.848608Z",
     "shell.execute_reply": "2024-06-12T01:24:26.847506Z",
     "shell.execute_reply.started": "2024-06-12T01:24:26.799659Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# normalize the embeddings\n",
    "train_embeddings = (train_embeddings - np.mean(train_embeddings, axis=0)) / np.std(train_embeddings, axis=0)\n",
    "val_embeddings = (val_embeddings - np.mean(val_embeddings, axis=0)) / np.std(val_embeddings, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c494bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T01:25:54.096588Z",
     "iopub.status.busy": "2024-06-12T01:25:54.096197Z",
     "iopub.status.idle": "2024-06-12T01:26:17.881351Z",
     "shell.execute_reply": "2024-06-12T01:26:17.880076Z",
     "shell.execute_reply.started": "2024-06-12T01:25:54.096549Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TRAIN\n",
    "ensemble_model = EnsembleModel(num_classes=4, input_dim=size)\n",
    "ensemble_model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(ensemble_model.parameters(), lr=0.0001)\n",
    "\n",
    "num_epochs = 5\n",
    "best_model_ensamble = None\n",
    "best_val_loss_ensamble = np.inf\n",
    "\n",
    "train_losses_ensamble = []\n",
    "val_losses_ensamble = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    ensemble_model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    # train\n",
    "    for i in range(len(train_embeddings)):\n",
    "        embeddings = train_embeddings[i]\n",
    "        labels = train_labels_eff[i]\n",
    "        \n",
    "        embeddings = torch.tensor(embeddings, dtype=torch.float32).to(device)\n",
    "        labels = torch.tensor(labels, dtype=torch.float32).to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = ensemble_model(embeddings)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    epoch_loss_train = running_loss / len(train_embeddings)\n",
    "    train_losses_ensamble.append(epoch_loss_train)\n",
    "    \n",
    "    \n",
    "    # validate\n",
    "    ensemble_model.eval()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i in range(len(train_embeddings)):\n",
    "        embeddings = train_embeddings[i]\n",
    "        labels = train_labels_eff[i]\n",
    "        \n",
    "        embeddings = torch.tensor(embeddings, dtype=torch.float32).to(device)\n",
    "        labels = torch.tensor(labels, dtype=torch.float32).to(device)\n",
    "        \n",
    "        outputs = ensemble_model(embeddings)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    epoch_loss_val = running_loss / len(train_embeddings)\n",
    "    val_losses_ensamble.append(epoch_loss_val)\n",
    "    \n",
    "    print(f\"Train Loss: {epoch_loss_train:.4f}, Val Loss: {epoch_loss_val:.4f}\")\n",
    "    \n",
    "    if epoch_loss_val < best_val_loss_ensamble:\n",
    "        best_val_loss_ensamble = epoch_loss_val\n",
    "        best_model_ensamble = copy.deepcopy(ensemble_model)\n",
    "        torch.save(best_model_ensamble.state_dict(), \"best_model_ensamble.pth\")\n",
    "        print(\"ensamble saved\")\n",
    "        \n",
    "        \n",
    "# save the final model\n",
    "torch.save(ensemble_model.state_dict(), \"final_model_ensamble.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f008fdab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T01:26:23.585123Z",
     "iopub.status.busy": "2024-06-12T01:26:23.584492Z",
     "iopub.status.idle": "2024-06-12T01:32:54.590108Z",
     "shell.execute_reply": "2024-06-12T01:32:54.589178Z",
     "shell.execute_reply.started": "2024-06-12T01:26:23.585090Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PREDICT\n",
    "# load the best model\n",
    "ensemble_model = EnsembleModel(num_classes=4, input_dim=size)\n",
    "ensemble_model.load_state_dict(torch.load(\"best_model_ensamble.pth\"))\n",
    "ensemble_model.to(device)\n",
    "\n",
    "# get the embeddings\n",
    "test_embeddings_eff, _ = get_all_embeddings(model_eff, test_loader_eff)\n",
    "test_embeddings_vit, _ = get_all_embeddings(model_vit, test_loader_vit)\n",
    "test_embeddings_res, _ = get_all_embeddings(model_res, test_loader_res)\n",
    "test_embeddings_vitb, _ = get_all_embeddings(model_vitb, test_loader_vitb)\n",
    "\n",
    "# combine the embeddings\n",
    "test_embeddings = np.concatenate([test_embeddings_eff, test_embeddings_vit, test_embeddings_res, test_embeddings_vitb], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67db89fc",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-06-12T01:33:06.623950Z",
     "iopub.status.busy": "2024-06-12T01:33:06.623014Z",
     "iopub.status.idle": "2024-06-12T01:33:06.633464Z",
     "shell.execute_reply": "2024-06-12T01:33:06.632251Z",
     "shell.execute_reply.started": "2024-06-12T01:33:06.623906Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_ensemble(model, test_embeddings):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(len(test_embeddings)):\n",
    "            embeddings = test_embeddings[i]\n",
    "            embeddings = torch.tensor(embeddings, dtype=torch.float32).to(device)\n",
    "            \n",
    "            #print(embeddings.shape)\n",
    "            outputs = model(embeddings)\n",
    "            outputs = outputs.unsqueeze(0)\n",
    "            #print(outputs)\n",
    "            #print(outputs.shape)\n",
    "            \n",
    "            probabilities = F.softmax(outputs, dim=1)\n",
    "            predictions.append(probabilities.cpu().numpy())\n",
    "            \n",
    "    return np.concatenate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2740c971",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T01:33:15.259579Z",
     "iopub.status.busy": "2024-06-12T01:33:15.258736Z",
     "iopub.status.idle": "2024-06-12T01:33:15.932275Z",
     "shell.execute_reply": "2024-06-12T01:33:15.931457Z",
     "shell.execute_reply.started": "2024-06-12T01:33:15.259547Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions_ensemble = predict_ensemble(ensemble_model, test_embeddings)\n",
    "\n",
    "# save the predictions\n",
    "submissions_ensemble = pd.DataFrame(predictions_ensemble, columns=[\"healthy\", \"multiple_diseases\", \"rust\", \"scab\"])\n",
    "submissions_ensemble[\"image_id\"] = test_df[\"image_id\"]\n",
    "submissions_ensemble = submissions_ensemble[[\"image_id\", \"healthy\", \"multiple_diseases\", \"rust\", \"scab\"]]\n",
    "submissions_ensemble.to_csv(\"submission_ensemble.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 1026645,
     "sourceId": 18648,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-12T16:03:06.403019",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
